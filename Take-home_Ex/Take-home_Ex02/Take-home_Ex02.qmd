---
title: "Take-home Exercise 2"
author: "SMLurker"
date: "18 May 2023"
execute: 
  warning: false
  echo: true
  eval: true
edit: visual
---

## 1. The Task

#### 1.1 Background

##### The country of Oceanus has sought FishEye International's help in identifying companies possibly engaged in illegal, unreported, and unregulated (IUU) fishing. As part of the collaboration, FishEye's analysts received import/export data for Oceanus' marine and fishing industries. However, Oceanus has informed FishEye that the data is incomplete. To facilitate their analysis, FishEye transformed the trade data into a knowledge graph. Using this knowledge graph, they hope to understand business relationships, including finding links that will help them stop IUU fishing and protect marine species that are affected by it. FishEye analysts found that node-link diagrams gave them a good high-level overview of the knowledge graph. However, they are now looking for visualizations that provide more detail about patterns for entities in the knowledge graph. There are two main parts to this analysis.

##### First, FishEye knows from past experience that companies caught fishing illegally will shut down but will then often start up again under a different name. FishEye wants your help to visualize temporal patterns so they can compare the activities of companies over time to determine if the companies have returned to their nefarious acts.

##### Second, FishEye has been using several tools, including artificial intelligence, to reason on the knowledge graph and suggest links that could extend the dataset. They have supplied 12 groups of link suggestions and need your help evaluating these groups to identify which tools are most reliable for completing the graph. FishEye is especially interested in identifying new temporal patterns or anomalies that are only present when new links are added.

##### Using visual analytics, can you help FishEye identify companies that may be engaged in illegal fishing?

#### 1.2 Introduction

##### With reference to bullet point 1 of Mini Challenge 2 of VAST Challenge 2023, it will be studied that:

###### Â  Use visual analytics to identify temporal patterns for individual entities and between entities in the knowledge graph FishEye created from trade records. Categorize the types of business relationship patterns you find. Limit your response to 600 words and 6 images.

## 2.Install packages, load data and data wrangling

#### 2.1 Load packages and data

```{r}
pacman::p_load(jsonlite,tidygraph, visNetwork,
               ggraph, tidyr, ggstatsplot,
               lubridate, plotly, gganimate, plotly,igraph,
               DT, tidyverse)
```

```{r}
MC2 <- jsonlite::fromJSON("data/mc2_challenge_graph.json")
```

#### 2.2 Expand MC2 nodes and links

```{r}
MC2_nodes <- as_tibble(MC2$nodes) %>%
  distinct() %>%
  select(id, shpcountry, rcvcountry)

MC2_links <- as_tibble(MC2$links) %>%
  mutate(ArrivalDate = ymd(arrivaldate)) %>%
  mutate(Year = year(ArrivalDate)) %>%
  select(source, target, arrivaldate, Year, hscode, valueofgoods_omu, volumeteu, weightkg, valueofgoodsusd) %>%
  distinct()
```

#### 2.3 Reviewing the imported data

##### Nodes

```{r}
#| code-fold: true
#| code-summary: "Show the code"
glimpse(MC2_nodes)
```

##### Edges

```{r}
#| code-fold: true
#| code-summary: "Show the code"
glimpse(MC2_links)
```

#### 2.4 Data preview

##### 2.4.1 Preparation for aggregated nodes and edges and select an example hscode and year to create a graph

```{r}
#| code-fold: true
#| code-summary: "Show the code"
MC2_edges_aggregated <- MC2_links %>%
  left_join(MC2_nodes, by = c("source" = "id")) %>%
  rename(from = source) %>%
  left_join(MC2_nodes, by = c("target" = "id")) %>%
  rename(to = target) %>%
  filter(hscode=="306170" & Year=="2028")%>%
  group_by(from, to) %>%
    summarise(weight = n()) %>%
  filter(from!=to) %>%
  filter(weight > 20) %>%
  ungroup()
MC2_nodes_aggregated <- MC2_nodes %>%
  filter(id %in% c(MC2_edges_aggregated$from, MC2_edges_aggregated$to))
```

```{r}
DT::datatable(MC2_nodes_aggregated, class= "compact")
```

```{r}
DT::datatable(MC2_edges_aggregated, class= "compact")
```

##### 2.4.2 Plot the graph

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#set.seed(123)
#edges <- MC2_edges_aggregated #%>% sample_frac(0.005)
#nodes <- MC2_nodes %>%
  #filter(id %in% c(edges$from, edges$to))
visNetwork(MC2_nodes_aggregated,
           MC2_edges_aggregated ) %>%
  visIgraphLayout(layout = "layout_with_fr") %>%
  visEdges(arrows = "to", 
           smooth = list(enabled = TRUE, 
                         type = "curvedCW"))
```

## 3. Visualization and Analysis

#### An overview of the temporal change of sampled edges within 2028 to 2034

##### Here we extract the edge data and group by year-month, and we can see the changes of the sum of weight and value_usd on a monthly changed base.Mostly the sum of weight is below 100k and value_usd below 0.6M.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
MC2_links$arrivalym <-  format(as.Date(MC2_links$arrivaldate),"%Y-%m")
MC2_edges_5 <- MC2_links %>% group_by(source,target,arrivalym) %>% 
  summarise(count_hscode=n_distinct(hscode),
            sum_omu=sum(valueofgoods_omu),
            sum_teu=sum(volumeteu),
            sum_weightkg=sum(weightkg),
            sum_usd=sum(valueofgoodsusd),.groups = 'drop') %>%
  
  as.data.frame()
MC2_edges_5 <- MC2_edges_5[complete.cases(MC2_edges_5[ , c('sum_weightkg', 'sum_usd')]), ]
set.seed(123)
MC2_nodes_5 <- MC2_nodes %>%
  filter(id %in% MC2_edges_5$source) %>% sample_frac(0.005)
MC2_edges_6 <- MC2_edges_5 %>%
  filter(MC2_edges_5$source %in% MC2_nodes_5$id) %>%
  filter(sum_weightkg< 2000000) %>%
  filter(sum_usd< 1000000)

  
bp <- MC2_edges_6 %>%
  plot_ly(x = ~sum_weightkg, 
          y = ~sum_usd, 
          size = ~sum_weightkg, 
          color = ~source,
          sizes = c(2, 100),
          frame = ~arrivalym, 
          text = ~target, 
          hoverinfo = "text",
          type = 'scatter',
          mode = 'markers'
          ) %>%
  layout(showlegend = FALSE)
bp

```

#### Comparison of distribution of mean avg_price records that have 1-7 years of history.

##### Here we pay attention to a yearly change in below and we found that companies that has only 1 year of record has the highest avg_price. Considering if a company is legally fishing, mostly they will form a long relationship with collaborators and the price is reasonable. But for companies that are caught illegal fishing or shut down, the price are more likely to be higher than the market and their record histories are also short.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
MC2_edges <- MC2_links[complete.cases(MC2_links[ , c('hscode','valueofgoodsusd','volumeteu')]), ] %>% 
  filter(hscode == "306170") %>%
  filter(weightkg != 0 ) %>% 
  mutate(price = valueofgoodsusd/weightkg)

MC2_edges_1 <- MC2_edges %>% 
  group_by(source,target,Year) %>% 
  summarise(No_of_time=n(),
            sum_omu=sum(valueofgoods_omu),
            sum_teu=sum(volumeteu),
            sum_weightkg=sum(weightkg),
            sum_usd=sum(valueofgoodsusd),
            mean_price=mean(price),.groups = 'drop') %>%
  as.data.frame()

MC2_edges_2 <- MC2_edges_1 %>% group_by(source,target) %>% 
  summarise(No_of_year=n_distinct(Year),
            avg_not=mean(No_of_time),
            avg_price=mean(mean_price),
            avg_weightkg=mean(sum_weightkg),.groups = 'drop') %>%
  #inner_join(edges, by = c("source"="from","target"="to")) %>%
  as.data.frame()


my_sum <- MC2_edges_2 %>%
  group_by(No_of_year) %>%
  summarise(
    n=n(),
    mean=mean(avg_price),
    sd=sd(avg_price)
    ) %>%
  mutate(se=sd/sqrt(n-1))

ggplot(my_sum) +
  geom_errorbar(
    aes(x=No_of_year, 
        ymin=mean-se, 
        ymax=mean+se), 
    width=0.2, 
    colour="black", 
    alpha=0.9, 
    size=0.5) +
  geom_point(aes
           (x=No_of_year, 
            y=mean), 
           stat="identity", 
           color="red",
           size = 1.5,
           alpha=1) +
  ggtitle("Standard error of mean avg_price score by No_of_year")
```

##### Stats table

```{r}
#| code-fold: true
#| code-summary: "Show the code"
knitr::kable(my_sum, format = 'html')
```

#### Further analysis on short-history edges

##### Here we filter with year=1 and plot out 10%

```{r}
#| code-fold: true
#| code-summary: "Show the code"
MC2_edges_2_aggregated <- MC2_edges_2 %>%
  left_join(MC2_nodes, by = c("source" = "id")) %>%
  rename(from = source) %>%
  left_join(MC2_nodes, by = c("target" = "id")) %>%
  rename(to = target) %>%
  filter(No_of_year==1)%>%
  filter(from!=to) %>%
  filter(avg_not>5)%>%
  ungroup()
MC2_nodes_2_aggregated <- MC2_nodes %>%
  filter(id %in% c(MC2_edges_2_aggregated$from, MC2_edges_2_aggregated$to))

visNetwork(MC2_nodes_2_aggregated,
           MC2_edges_2_aggregated ) %>%
  visIgraphLayout(layout = "layout_with_fr") %>%
  visEdges(arrows = "to", 
           smooth = list(enabled = TRUE, 
                         type = "curvedCW"))
```

##### the top 10% vertices based on their eigenvector centrality score

```{r}
#| code-fold: true
#| code-summary: "Show the code"
cgraph <- graph_from_data_frame (MC2_edges_2_aggregated,
                           vertices = MC2_nodes_2_aggregated) %>%
  as_tbl_graph()
quantile_graph <- quantile(eigen_centrality(cgraph)$vector,
         probs = seq(0, 1, 1/10)
         )
V(cgraph)$size = eigen_centrality(cgraph)$vector

cgraph_aggregated <- delete_vertices(cgraph, V(cgraph)[size < quantile_graph[10]])


set.seed (1234)
layout1 <- layout_with_fr(cgraph_aggregated)

quantile_graph_aggregated <- quantile(V(cgraph_aggregated)$size, #identify top 10% of the new vertices
         probs = seq(0, 1, 1/10)
         )


V(cgraph_aggregated)$color <- ifelse (V(cgraph_aggregated)$size > quantile_graph_aggregated[10], "darkgoldenrod3", "azure3") #color yellow if vertices is top 10%
E(cgraph_aggregated)$color <- "grey"
V(cgraph_aggregated)$size <- V(cgraph_aggregated)$size/0.065 
#Increase the size of nodes based on their centrality score, only those with high score will be visible

V(cgraph_aggregated)$label <- ifelse (V(cgraph_aggregated)$size*0.065 > quantile_graph_aggregated[10],V(cgraph_aggregated)$name,NA)
#label the vertices if vertices belongs to the top 10%

plot(cgraph_aggregated, edge.arrow.size=0.25,edge.arrow.mode = "-", vertex.label = V(cgraph_aggregated)$label, vertex.label.cex = 0.65, vertex.label.font = 1, main = "Which IDs has the most shipments within 1 year?" ) 

```

##### Here we have the attributes of the top 10% vertices based on the updated EigenVector Centrality.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
vertex_attr(cgraph_aggregated, index = V(cgraph_aggregated)$size*0.065 > quantile_graph_aggregated[10])
```

##### detect possible cluster based on the betweeness score of the vertices

```{r}
#| code-fold: true
#| code-summary: "Show the code"
GNC <- cluster_edge_betweenness(cgraph_aggregated, weights = NULL)
V(cgraph_aggregated)$color <-membership(GNC)              
cgraph_aggregated$palette <- diverging_pal(length(GNC)) 
plot(cgraph_aggregated, edge.arrow.size=0.25,edge.arrow.mode = "-", vertex.label = NA, main = "How many Social Groups within the category?")

```

##### Here according to the results above, we can make an hypothesis that since FishEye knows from past experience that companies caught fishing illegally will shut down but will then often start up again under a different name, and we find out that companies that have only 1 year of transactions history ofter have the highest avg_price, it is very likely that among these, the trade records may have problems. And we focus on top 10% as it is weird that these companies disappeared in the second year if they fish legally since the trade record is more frequent. These companies and records should be well-studied to further find out more IUU fishing behaviors.
