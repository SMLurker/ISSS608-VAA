[
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#install-launch-r-packages-load-data-and-build-data-table",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#install-launch-r-packages-load-data-and-build-data-table",
    "title": "Take-home Exercise 1",
    "section": "4. Install, launch R packages, load data and build data table",
    "text": "4. Install, launch R packages, load data and build data table\n\n4.1 Reading the participants csv and build interactive paticipants table\n\n\nShow the code\npacman::p_load(tidyverse,dplyr,DT,plotly, ggdist,gganimate,ggstatsplot,ggiraph,ggridges, ggthemes)\n\n\n\n\nShow the code\np_data <- read_csv(\"data/Participants.csv\") %>% \n  mutate_if(is.character, as.factor) %>% \n  distinct()\nDT::datatable(p_data, class= \"compact\")\n\n\n\n\n\n\n\n\n\n \n\n\n4.2 Modify the time style of the financial data, pivot the catogory and regroup, calculate the Savings, and build interactive FinancialJournal table\n\n\nShow the code\nfin_data <- read_csv(\"data/FinancialJournal.csv\") %>% \n  mutate_if(is.character, as.factor) %>% distinct() \nfin_data$timestamp <- format(as.Date(fin_data$timestamp), \"%Y-%m\")\nf_data <- fin_data %>% group_by(participantId,timestamp,category) %>% \n  summarise(total_amount=sum(amount),\n            .groups = 'drop') %>%\n  as.data.frame()\nf_data <- f_data %>%\n  pivot_wider(.,names_from = \"category\", values_from = \"total_amount\") \nf_data <- replace(f_data, is.na(f_data), 0) %>%\n    mutate(Saving = select(., Education:RentAdjustment) %>% rowSums(na.rm = TRUE))\nDT::datatable(f_data, class= \"compact\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#analysis-and-visualization",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#analysis-and-visualization",
    "title": "Take-home Exercise 1",
    "section": "5. Analysis and visualization",
    "text": "5. Analysis and visualization\n\n5.1 Figure out the relationship of educationLevel and Joviality\n\nOverall, we see from below that with the increasing of education level, people tend to have higher level of joviality as the lower bound and mean value of joviality has a trend to increase. Although we can also observe that for low level of education, the range is bigger that all other level, this might indicate longer social experience can still affect the upper bound of joviality, but enhancing education is still a more direct way to increase joviality level.\n\nThe plotThe codeThe statistics table\n\n\n\n\n\n\n\n\n\n\ndf <- f_data %>% group_by(participantId) %>% \n  summarise(total_edu=sum(Education),\n            total_food=sum(Food),\n            total_rec=sum(Recreation),\n            total_shl=sum(Shelter),\n            total_w=sum(Wage),\n            total_rent=sum(RentAdjustment),\n            total_saving=sum(Saving),\n            .groups = 'drop') %>%\n  as.data.frame()\ndf2 <- merge(x= df,y= p_data, by = \"participantId\")\n\ndf3 <- fin_data %>%                              # Applying group_by & summarise\n  group_by(participantId) %>%\n  summarise(count_month = n_distinct(timestamp)) %>%\n  filter(count_month>1)\ndf4 <-merge(x=df3,y=df2, \n             by=\"participantId\", all.x=TRUE)\n\nmy_sum <- df4 %>%\n  group_by(educationLevel) %>%\n  summarise(\n    n=n(),\n    mean=mean(joviality),\n    sd=sd(joviality)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=educationLevel, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=educationLevel, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  scale_x_discrete(limits = c(\"Low\", \"HighSchoolOrCollege\", \"Bachelors\", \"Graduate\")) +\n  ggtitle(\"Standard error of mean \n          Joviality score by educationLevel\")\n\n\n\n\nsumm <- my_sum[order(factor(my_sum$educationLevel, levels = c(\"Low\", \"HighSchoolOrCollege\", \"Bachelors\", \"Graduate\"))),c(\"educationLevel\",\"n\",\"mean\",\"sd\")]\nknitr::kable(head(summ), format = 'html')\n\n\n\n \n  \n    educationLevel \n    n \n    mean \n    sd \n  \n \n\n  \n    Low \n    56 \n    0.4187639 \n    0.2937796 \n  \n  \n    HighSchoolOrCollege \n    422 \n    0.4346854 \n    0.2724155 \n  \n  \n    Bachelors \n    232 \n    0.4975164 \n    0.2976517 \n  \n  \n    Graduate \n    170 \n    0.5162219 \n    0.2969368 \n  \n\n\n\n\n\n\n\n\n\n\n\n5.2 Figure out the relationship of householdSize and Joviality\n\nFrom the plotting below, we see that number of householdSize does not have huge effect on the median of Joviality but there is still some slight impact that household with 2 or more people tend to have a middle or low level of joviality while one person are more intend to be either with high or low joviality.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = df4,\n  x = householdSize, \n  y = joviality,\n  type = \"np\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n5.3 Savings and Joviality\n\nfrom the graph below, we can find that the saving of most people are below 50000 within the study period.\n\n\nShow the code\ngghistostats(\n  data = df4,\n  x = total_saving,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"total_saving\"\n)\n\n\n\n\n\n\n\nConsider the Engel’s coefficient, which is simply a food budget share, it is used for this purpose by The United Nations (UN), where a coefficient above 59% represents poverty, 50-59% represents a state where daily needs are barely met, 40-50% a moderately well-off standard of living, 30-40% a good standard of living and below 30% a wealthy life. It can be seem here overall the Engel’s coefficients of the households do not have significant change, but there are still some household above 60%.\n\n\nShow the code\ndf5 <- data.frame(f_data)\ndf5$RentAdjustment[df5$RentAdjustment>0] <- 0\ndf5 <- df5[df5$timestamp!='2022-03',]\ndf5 <- df5[df5$timestamp!='2023-02',]\ndf5$cost <- df5$Education+df5$Food+df5$Recreation+df5$Shelter+df5$RentAdjustment\n\ndf6 <- df5 %>% group_by(participantId, timestamp) %>% \n  summarise(mon_saving=sum(Saving),\n            mon_cost=sum(cost),\n            mon_food=sum(Food),\n            .groups = 'drop') %>%\n  as.data.frame()\n\ngg <- ggplot(df6, \n       aes(x = -mon_food, \n           y = mon_food/mon_cost, \n           size = -mon_cost, \n           colour = participantId)) +\n  geom_point(aes(size = -mon_cost,\n                 frame = timestamp),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_size(range = c(1, 5)) +\n  labs(x = 'mon_food', \n       y = 'Engel\\'s Coefficient')\n\nggplotly(gg)\n\n\n\n\n\n\n\n\n\n5.4 InterestGroup and Joviality\n\nIt seems that most interest groups has a mean joviality value around 0.4 and has similar joviality distribution, but groups like D or H should be paid more attention to. But overall, interest groups promote freedom of expression, explore new perspectives, and allow people of all level of joviality to gather, to share and to express.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(df4, \n       aes(x = interestGroup, \n           y = joviality)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA,\n               slab_fill = \"light blue\") +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#figure-out-the-relationship-of-householdsize-and-joviality",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#figure-out-the-relationship-of-householdsize-and-joviality",
    "title": "Take-home Exercise 1",
    "section": "5.2 Figure out the relationship of householdSize and Joviality",
    "text": "5.2 Figure out the relationship of householdSize and Joviality\n\nFrom the plotting below, we see that number of householdSize does not have huge effect on Joviality but there is still some slight impact that household with 2 or more people tend to have a bit higher mean joviality than 1 person and 2 people have the hight mean.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = df2,\n  x = householdSize, \n  y = joviality,\n  type = \"np\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#next",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#next",
    "title": "Take-home Exercise 1",
    "section": "Next",
    "text": "Next\n\ngghistostats(\n  data = df2,\n  x = total_saving,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"total_saving\"\n)\n\n\n\n\n\nplot_ly(data = df2, \n        x = ~total_saving, \n        y = ~joviality, \n        color = ~interestGroup)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#distribution-of-savings",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#distribution-of-savings",
    "title": "Take-home Exercise 1",
    "section": "Distribution of savings",
    "text": "Distribution of savings\n\nfrom the graph below, we can find that the saving of most people are below 50000 within the study period.\n\ngghistostats(\n  data = df2,\n  x = total_saving,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"total_saving\"\n)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#and-by-plotting-the-ralationship-of-savings-interestgroups-and-joviality-we-can-see-that-no-matter-how-much-people-save-they-are-still-willing-to-join-any-kinds-of-interest-groups.",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#and-by-plotting-the-ralationship-of-savings-interestgroups-and-joviality-we-can-see-that-no-matter-how-much-people-save-they-are-still-willing-to-join-any-kinds-of-interest-groups.",
    "title": "Take-home Exercise 1",
    "section": "And by plotting the ralationship of savings, interestGroups and joviality, we can see that no matter how much people save, they are still willing to join any kinds of interest groups.",
    "text": "And by plotting the ralationship of savings, interestGroups and joviality, we can see that no matter how much people save, they are still willing to join any kinds of interest groups.\n\nplot_ly(data = df2, \n        x = ~total_saving, \n        y = ~joviality, \n        color = ~interestGroup)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conclusion",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conclusion",
    "title": "Take-home Exercise 1",
    "section": "Conclusion",
    "text": "Conclusion\n\nTherefore, in order to assist with the major community revitalization efforts, the very large city renewal grant they have recently received should be allocated as below:\n\n 1.Invest in high-quality teachers, provide resources and support for schools and universities and utilize technology like online learning platforms and educational software to encourage people to gain knowledge and improve education qualification\n\n\n 2.Help poor people to gain more skills and develop working opportunities for them to increase their salary. Increase the overall Engel’s Coefficient value to reduce proverty and improve the living condition of households.\n\n\n 3.Make dating apps, matchmaking services, holding networking events or other method to help single people conveniently meet and connect with like-minded people and find a partner\n\n\n 4.Setup community service, hold activities and interest groups to provide people with opportunities to meet people of same interests."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "pacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\n\n\n\n\nGAStech_nodes <- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges <- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\n\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      <dbl> 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      <dbl> 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    <chr> \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    <time> 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     <chr> \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject <chr> \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel <chr> \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel <chr> \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\nGAStech_edges <- GAStech_edges %>%\n  mutate(SendDate = dmy(SentDate)) %>%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\nGAStech_edges_aggregated <- GAStech_edges %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(source, target, Weekday) %>%\n    summarise(Weight = n()) %>%\n  filter(source!=target) %>%\n  filter(Weight > 1) %>%\n  ungroup()\n\n\n\n\n\n\n\n\nGAStech_graph <- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 54 × 4\n     id label               Department     Title                                \n  <dbl> <chr>               <chr>          <chr>                                \n1     1 Mat.Bramar          Administration Assistant to CEO                     \n2     2 Anda.Ribera         Administration Assistant to CFO                     \n3     3 Rachel.Pantanal     Administration Assistant to CIO                     \n4     4 Linda.Lagos         Administration Assistant to COO                     \n5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Manag…\n6     6 Carla.Forluniau     Administration Assistant to IT Group Manager        \n# ℹ 48 more rows\n#\n# A tibble: 1,372 × 4\n   from    to Weekday Weight\n  <int> <int> <ord>    <int>\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\n\n\n\n\nGAStech_graph %>%\n  activate(edges) %>%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 1,372 × 4\n   from    to Weekday  Weight\n  <int> <int> <ord>     <int>\n1    40    41 Saturday     13\n2    41    43 Monday       11\n3    35    31 Tuesday      10\n4    40    41 Monday       10\n5    40    43 Monday       10\n6    36    32 Sunday        9\n# ℹ 1,366 more rows\n#\n# A tibble: 54 × 4\n     id label           Department     Title           \n  <dbl> <chr>           <chr>          <chr>           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\n\n\n\n\n\n\n\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\ng <- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\ng <- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\n\ng <- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\nset_graph_style() \n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n\ng <- GAStech_graph %>%\n  mutate(betweenness_centrality = centrality_betweenness()) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\ng <- GAStech_graph %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\n\ng <- GAStech_graph %>%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\nGAStech_edges_aggregated <- GAStech_edges %>%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %>%\n  rename(from = id) %>%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %>%\n  rename(to = id) %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(from, to) %>%\n    summarise(weight = n()) %>%\n  filter(from!=to) %>%\n  filter(weight > 1) %>%\n  ungroup()\n\n\n\n\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\n\n\n\nGAStech_nodes <- GAStech_nodes %>%\n  rename(group = Department) \n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Application. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01 - v2.html#install-launch-r-packages-load-data-and-build-data-table",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01 - v2.html#install-launch-r-packages-load-data-and-build-data-table",
    "title": "Take-home Exercise 1",
    "section": "4. Install, launch R packages, load data and build data table",
    "text": "4. Install, launch R packages, load data and build data table\n\nReading the paticipants csv and build interactive paticipants table\n\n\nShow the code\npacman::p_load(tidyverse,dplyr,DT,plotly, ggdist,gganimate,ggstatsplot,ggiraph)\n\n\n\n\nShow the code\np_data <- read_csv(\"data/Participants.csv\") %>% \n  mutate_if(is.character, as.factor) %>% \n  distinct()\nDT::datatable(p_data, class= \"compact\")\n\n\n\n\n\n\n\n\n\nModify the time style of the financial data, pivot the catogory and regroup, calculate the Savings, and build interactive FinancialJournal table\n\n\nShow the code\nfin_data <- read_csv(\"data/FinancialJournal.csv\") %>% \n  mutate_if(is.character, as.factor) %>% distinct() \nfin_data$timestamp <- format(as.Date(fin_data$timestamp), \"%Y-%m\")\nf_data <- fin_data %>% group_by(participantId,timestamp,category) %>% \n  summarise(total_amount=sum(amount),\n            .groups = 'drop') %>%\n  as.data.frame()\nf_data <- f_data %>%\n  pivot_wider(.,names_from = \"category\", values_from = \"total_amount\") \nf_data <- replace(f_data, is.na(f_data), 0) %>%\n    mutate(Saving = select(., Education:RentAdjustment) %>% rowSums(na.rm = TRUE))\nDT::datatable(f_data, class= \"compact\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01 - v2.html#analysis-and-visualization",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01 - v2.html#analysis-and-visualization",
    "title": "Take-home Exercise 1",
    "section": "5. Analysis and visualization",
    "text": "5. Analysis and visualization\n\n5.1 Figure out the relationship of educationLevel and Joviality\n\nOverall, we see from below that with the increasing of education level, people tend to have higher level of joviality as the lower bound and mean value of joviality has a trend to increase. Although we can also observe that for low level of education, the range is bigger that all other level, this might indicate longer social experience can still affect the upper bound of joviality, but enhancing education is still a more direct way to increase joviality level.\n\nThe plotThe codeThe statistics table\n\n\n\n\n\n\n\n\n\n\ndf <- f_data %>% group_by(participantId) %>% \n  summarise(total_edu=sum(Education),\n            total_food=sum(Food),\n            total_rec=sum(Recreation),\n            total_shl=sum(Shelter),\n            total_w=sum(Wage),\n            total_rent=sum(RentAdjustment),\n            total_saving=sum(Saving),\n            .groups = 'drop') %>%\n  as.data.frame()\ndf2 <- merge(x= df,y= p_data, by = \"participantId\")\n\ndf3 <- fin_data %>%                              # Applying group_by & summarise\n  group_by(participantId) %>%\n  summarise(count_month = n_distinct(timestamp)) %>%\n  filter(count_month>1)\ndf4 <-merge(x=df3,y=df2, \n             by=\"participantId\", all.x=TRUE)\n\nmy_sum <- df4 %>%\n  group_by(educationLevel) %>%\n  summarise(\n    n=n(),\n    mean=mean(joviality),\n    sd=sd(joviality)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=educationLevel, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=educationLevel, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  scale_x_discrete(limits = c(\"Low\", \"HighSchoolOrCollege\", \"Bachelors\", \"Graduate\")) +\n  ggtitle(\"Standard error of mean \n          Joviality score by educationLevel\")\n\n\n\n\nsumm <- my_sum[order(factor(my_sum$educationLevel, levels = c(\"Low\", \"HighSchoolOrCollege\", \"Bachelors\", \"Graduate\"))),c(\"educationLevel\",\"n\",\"mean\",\"sd\")]\nknitr::kable(head(summ), format = 'html')\n\n\n\n \n  \n    educationLevel \n    n \n    mean \n    sd \n  \n \n\n  \n    Low \n    56 \n    0.4187639 \n    0.2937796 \n  \n  \n    HighSchoolOrCollege \n    422 \n    0.4346854 \n    0.2724155 \n  \n  \n    Bachelors \n    232 \n    0.4975164 \n    0.2976517 \n  \n  \n    Graduate \n    170 \n    0.5162219 \n    0.2969368 \n  \n\n\n\n\n\n\n\n\n\n\n\n5.2 Figure out the relationship of householdSize and Joviality\n\nFrom the plotting below, we see that number of householdSize does not have huge effect on the median of Joviality but there is still some slight impact that household with 2 or more people tend to have a middle or low level of joviality while one person are more intend to be either with high or low joviality\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = df4,\n  x = householdSize, \n  y = joviality,\n  type = \"np\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n5.3 Money and Joviality\n\nfrom the graph below, we can find that the saving of most people are below 50000 within the study period.\n\n\nShow the code\ngghistostats(\n  data = df4,\n  x = total_saving,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"total_saving\"\n)\n\n\n\n\n\n\n\n\nAnd by plotting the ralationship of wages and joviality, we can high wages does not really mean for high joviality.\n\n\nShow the code\nggscatterstats(\n  data = df4,\n  x = total_w,\n  y = joviality,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n5.4 InterestGroup and Joviality\n\nIt seems that most interest groups has a mean joviality value around 0.5 and has similar joviality distribution, but groups like D or H should be paid more attention to.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ntooltip <- function(y, ymax, accuracy = .01) {\n  mean <- scales::number(y, accuracy = accuracy)\n  sem <- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean Joviality scores:\", mean, \"+/-\", sem)\n}\n\ngg_point <- ggplot(data=df4, \n                   aes(x = interestGroup),\n) +\n  stat_summary(aes(y = joviality, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = joviality),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )+\n  coord_cartesian(ylim=c(0,0.8))\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01 - v2.html#conclusion",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01 - v2.html#conclusion",
    "title": "Take-home Exercise 1",
    "section": "Conclusion",
    "text": "Conclusion\n\nTherefore, in order to assist with the major community revitalization efforts, the very large city renewal grant they have recently received should be allocated as below:\n\n Invest in high-quality teachers, provide resources and support for schools and universities and utilize technology like online learning platforms and educational software to encourage people to gain knowledge and improve education qualification\n\n\n Make dating apps, matchmaking services, holding networking events or other method to help single people conveniently meet and connect with like-minded people and find a partner\n\n\n Setup community service, hold activities and interest groups to provide people with opportunities to meet people of same interests."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5",
    "section": "",
    "text": "pacman::p_load(jsonlite,tidygraph,ggraph, visNetwork,tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#load-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#load-data",
    "title": "In-class Exercise 5",
    "section": "Load data",
    "text": "Load data\n\nMC1 <- jsonlite::fromJSON(\"data/MC1.json\")\n\n\nExpand MC1_nodes\n\nMC1_nodes <- as_tibble(MC1$nodes) %>%\n  select(id, type, country)\n\n\n\nExpand MC1_edges\n\nMC1_edges <- as_tibble(MC1$links) %>%\n  select(source,target,type,weight,key)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-task",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-task",
    "title": "Take-home Exercise 1",
    "section": "2. The Task",
    "text": "2. The Task\n\nIn this take-home exercise, you are required to apply the concepts and methods you had learned in Lesson 1-4 to reveal the demographic and financial characteristics of the city of Engagement, using appropriate static and interactive statistical graphics methods. This exercise requires a user-friendly and interactive solution that helps city managers and planners to explore the complex data in an engaging way and reveal hidden patterns. The data should be processed by using appropriate tidyverse family of packages and the statistical graphics must be prepared using ggplot2 and its extensions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-description",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-description",
    "title": "Take-home Exercise 1",
    "section": "3. Data Description",
    "text": "3. Data Description\n\nFor the purpose of this study, two data sets are provided. They are:\n\n\nParticipants.csv: Contains information about the residents of City of Engagement that have agreed to participate in this study.\n\n\n\n\n\n\nDetails of the csv\n\n\n\n\n\n  participantId (integer): unique ID assigned to each participant.\n  householdSize (integer): the number of people in the participant’s household\n  haveKids (boolean): whether there are children living in the participant’s household.\n  age (integer): participant’s age in years at the start of the study.\n  educationLevel (string factor): the participant’s education level, one of: {“Low”, “HighSchoolOrCollege”, “Bachelors”, “Graduate”}\n  interestGroup (char): a char representing the participant’s stated primary interest group, one of {“A”, “B”, “C”, “D”, “E”, “F”, “G”, “H”, “I”, “J”}. Note: specific topics of interest have been redacted to avoid bias.\n  joviality (float): a value ranging from [0,1] indicating the participant’s overall happiness level at the start of the study.\n\n\n\n\n\nFinancialJournal.csv: Contains information about financial transactions.\n\n\n\n\n\n\nDetails of the csv\n\n\n\n\n\n  participantId (integer): unique ID corresponding to the participant affected\n  timestamp (datetime): the time when the check-in was logged\n  category (string factor): a string describing the expense category, one of {“Education”, “Food”, “Recreation”, “RentAdjustment”, “Shelter”, “Wage”}\n  amount (double): the amount of the transaction"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "pacman::p_load(rstatix, gt, patchwork, tidyverse)\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam_data, aes(sample=ENGLISH))+\n  stat_qq() + \n  stat_qq_line()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can see that the points deviate significantly from the straight diagonal line. This is a clear indication that the set of data is not normally distributed.\n\n\n\n\n\n\nThe plotThe code trunk\n\n\n\n\n\n\n\n\n\n\nqq <- ggplot(exam_data, aes(sample=ENGLISH))+\n  stat_qq() + \n  stat_qq_line()\n\nsw_t <- exam_data %>%\n  shapiro_test(ENGLISH) %>%\n  gt()\n\ntmp <- tempfile(fileext = '.png')\ngtsave(sw_t, tmp)\ntable_png <- png::readPNG(tmp,native=TRUE)\n\nqq + table_png"
  },
  {
    "objectID": "Take-home_Ex/Take_home_Ex02/Take_home_Ex02.html#install-packages-load-data-and-data-wrangling",
    "href": "Take-home_Ex/Take_home_Ex02/Take_home_Ex02.html#install-packages-load-data-and-data-wrangling",
    "title": "Take-home Exercise 2",
    "section": "2.Install packages, load data and data wrangling",
    "text": "2.Install packages, load data and data wrangling\n\n2.1 Load packages and data\n\npacman::p_load(jsonlite,tidygraph, visNetwork,\n               ggraph, tidyr, ggstatsplot,\n               lubridate, plotly, gganimate, plotly,igraph,\n               DT, tidyverse)\n\n\nMC2 <- jsonlite::fromJSON(\"data/mc2_challenge_graph.json\")\n\n\n\n2.2 Expand MC2 nodes and links\n\nMC2_nodes <- as_tibble(MC2$nodes) %>%\n  distinct() %>%\n  select(id, shpcountry, rcvcountry)\n\nMC2_links <- as_tibble(MC2$links) %>%\n  mutate(ArrivalDate = ymd(arrivaldate)) %>%\n  mutate(Year = year(ArrivalDate)) %>%\n  select(source, target, arrivaldate, Year, hscode, valueofgoods_omu, volumeteu, weightkg, valueofgoodsusd) %>%\n  distinct()\n\n\n\n2.3 Reviewing the imported data\n\nNodes\n\n\nShow the code\nglimpse(MC2_nodes)\n\n\nRows: 34,576\nColumns: 3\n$ id         <chr> \"AquaDelight Inc and Son's\", \"BaringoAmerica Marine Ges.m.b…\n$ shpcountry <chr> \"Polarinda\", NA, \"Oceanus\", NA, \"Oceanus\", \"Kondanovia\", NA…\n$ rcvcountry <chr> \"Oceanus\", NA, \"Oceanus\", NA, \"Oceanus\", \"Utoporiana\", NA, …\n\n\n\n\nEdges\n\n\nShow the code\nglimpse(MC2_links)\n\n\nRows: 5,309,087\nColumns: 9\n$ source           <chr> \"AquaDelight Inc and Son's\", \"AquaDelight Inc and Son…\n$ target           <chr> \"BaringoAmerica Marine Ges.m.b.H.\", \"BaringoAmerica M…\n$ arrivaldate      <chr> \"2034-02-12\", \"2034-03-13\", \"2028-02-07\", \"2028-02-23…\n$ Year             <dbl> 2034, 2034, 2028, 2028, 2028, 2028, 2028, 2028, 2028,…\n$ hscode           <chr> \"630630\", \"630630\", \"470710\", \"470710\", \"470710\", \"47…\n$ valueofgoods_omu <dbl> 141015, 141015, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ volumeteu        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ weightkg         <int> 4780, 6125, 10855, 11250, 11165, 11290, 9000, 19490, …\n$ valueofgoodsusd  <dbl> NA, NA, NA, NA, NA, NA, 87110, 188140, NA, 221110, 58…\n\n\n\n\n\n2.4 Data preview\n\n2.4.1 Preparation for aggregated nodes and edges and select an example hscode and year to create a graph\n\n\nShow the code\nMC2_edges_aggregated <- MC2_links %>%\n  left_join(MC2_nodes, by = c(\"source\" = \"id\")) %>%\n  rename(from = source) %>%\n  left_join(MC2_nodes, by = c(\"target\" = \"id\")) %>%\n  rename(to = target) %>%\n  filter(hscode==\"306170\" & Year==\"2028\")%>%\n  group_by(from, to) %>%\n    summarise(weight = n()) %>%\n  filter(from!=to) %>%\n  filter(weight > 20) %>%\n  ungroup()\nMC2_nodes_aggregated <- MC2_nodes %>%\n  filter(id %in% c(MC2_edges_aggregated$from, MC2_edges_aggregated$to))\n\n\n\nDT::datatable(MC2_nodes_aggregated, class= \"compact\")\n\n\n\n\n\n\n\nDT::datatable(MC2_edges_aggregated, class= \"compact\")\n\n\n\n\n\n\n\n\n2.4.2 Plot the graph\n\n\nShow the code\n#set.seed(123)\n#edges <- MC2_edges_aggregated #%>% sample_frac(0.005)\n#nodes <- MC2_nodes %>%\n  #filter(id %in% c(edges$from, edges$to))\nvisNetwork(MC2_nodes_aggregated,\n           MC2_edges_aggregated ) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\"))"
  },
  {
    "objectID": "Take-home_Ex/Take_home_Ex02/Take_home_Ex02.html#visualization-and-analysis",
    "href": "Take-home_Ex/Take_home_Ex02/Take_home_Ex02.html#visualization-and-analysis",
    "title": "Take-home Exercise 2",
    "section": "3. Visualization and Analysis",
    "text": "3. Visualization and Analysis\n\nAn overview of the temporal change of sampled edges within 2028 to 2034\n\nHere we extract the edge data and group by year-month, and we can see the changes of the sum of weight and value_usd on a monthly changed base.Mostly the sum of weight is below 100k and value_usd below 0.6M.\n\n\nShow the code\nMC2_links$arrivalym <-  format(as.Date(MC2_links$arrivaldate),\"%Y-%m\")\nMC2_edges_5 <- MC2_links %>% group_by(source,target,arrivalym) %>% \n  summarise(count_hscode=n_distinct(hscode),\n            sum_omu=sum(valueofgoods_omu),\n            sum_teu=sum(volumeteu),\n            sum_weightkg=sum(weightkg),\n            sum_usd=sum(valueofgoodsusd),.groups = 'drop') %>%\n  \n  as.data.frame()\nMC2_edges_5 <- MC2_edges_5[complete.cases(MC2_edges_5[ , c('sum_weightkg', 'sum_usd')]), ]\nset.seed(123)\nMC2_nodes_5 <- MC2_nodes %>%\n  filter(id %in% MC2_edges_5$source) %>% sample_frac(0.005)\nMC2_edges_6 <- MC2_edges_5 %>%\n  filter(MC2_edges_5$source %in% MC2_nodes_5$id) %>%\n  filter(sum_weightkg< 2000000) %>%\n  filter(sum_usd< 1000000)\n\n  \nbp <- MC2_edges_6 %>%\n  plot_ly(x = ~sum_weightkg, \n          y = ~sum_usd, \n          size = ~sum_weightkg, \n          color = ~source,\n          sizes = c(2, 100),\n          frame = ~arrivalym, \n          text = ~target, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %>%\n  layout(showlegend = FALSE)\nbp\n\n\n\n\n\n\n\n\n\nComparison of distribution of mean avg_price records that have 1-7 years of history.\n\nHere we pay attention to a yearly change in below and we found that companies that has only 1 year of record has the highest avg_price. Considering if a company is legally fishing, mostly they will form a long relationship with collaborators and the price is reasonable. But for companies that are caught illegal fishing or shut down, the price are more likely to be higher than the market and their record histories are also short.\n\n\nShow the code\nMC2_edges <- MC2_links[complete.cases(MC2_links[ , c('hscode','valueofgoodsusd','volumeteu')]), ] %>% \n  filter(hscode == \"306170\") %>%\n  filter(weightkg != 0 ) %>% \n  mutate(price = valueofgoodsusd/weightkg)\n\nMC2_edges_1 <- MC2_edges %>% \n  group_by(source,target,Year) %>% \n  summarise(No_of_time=n(),\n            sum_omu=sum(valueofgoods_omu),\n            sum_teu=sum(volumeteu),\n            sum_weightkg=sum(weightkg),\n            sum_usd=sum(valueofgoodsusd),\n            mean_price=mean(price),.groups = 'drop') %>%\n  as.data.frame()\n\nMC2_edges_2 <- MC2_edges_1 %>% group_by(source,target) %>% \n  summarise(No_of_year=n_distinct(Year),\n            avg_not=mean(No_of_time),\n            avg_price=mean(mean_price),\n            avg_weightkg=mean(sum_weightkg),.groups = 'drop') %>%\n  #inner_join(edges, by = c(\"source\"=\"from\",\"target\"=\"to\")) %>%\n  as.data.frame()\n\n\nmy_sum <- MC2_edges_2 %>%\n  group_by(No_of_year) %>%\n  summarise(\n    n=n(),\n    mean=mean(avg_price),\n    sd=sd(avg_price)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=No_of_year, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=No_of_year, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean avg_price score by No_of_year\")\n\n\n\n\n\n\n\nStats table\n\n\nShow the code\nknitr::kable(my_sum, format = 'html')\n\n\n\n\n \n  \n    No_of_year \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    1 \n    4387 \n    10.93051 \n    4.400719 \n    0.0664491 \n  \n  \n    2 \n    1410 \n    10.70853 \n    2.746642 \n    0.0731723 \n  \n  \n    3 \n    713 \n    10.82606 \n    2.299127 \n    0.0861634 \n  \n  \n    4 \n    358 \n    10.66151 \n    1.886805 \n    0.0998603 \n  \n  \n    5 \n    250 \n    10.60475 \n    2.499360 \n    0.1583905 \n  \n  \n    6 \n    225 \n    10.58984 \n    1.293865 \n    0.0864500 \n  \n  \n    7 \n    207 \n    10.60920 \n    1.082008 \n    0.0753871 \n  \n\n\n\n\n\n\n\n\nFurther analysis on short-history edges\n\nHere we filter with year=1 and plot out 10%\n\n\nShow the code\nMC2_edges_2_aggregated <- MC2_edges_2 %>%\n  left_join(MC2_nodes, by = c(\"source\" = \"id\")) %>%\n  rename(from = source) %>%\n  left_join(MC2_nodes, by = c(\"target\" = \"id\")) %>%\n  rename(to = target) %>%\n  filter(No_of_year==1)%>%\n  filter(from!=to) %>%\n  filter(avg_not>5)%>%\n  ungroup()\nMC2_nodes_2_aggregated <- MC2_nodes %>%\n  filter(id %in% c(MC2_edges_2_aggregated$from, MC2_edges_2_aggregated$to))\n\nvisNetwork(MC2_nodes_2_aggregated,\n           MC2_edges_2_aggregated ) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\"))\n\n\n\n\n\n\n\n\nthe top 10% vertices based on their eigenvector centrality score\n\n\nShow the code\ncgraph <- graph_from_data_frame (MC2_edges_2_aggregated,\n                           vertices = MC2_nodes_2_aggregated) %>%\n  as_tbl_graph()\nquantile_graph <- quantile(eigen_centrality(cgraph)$vector,\n         probs = seq(0, 1, 1/10)\n         )\nV(cgraph)$size = eigen_centrality(cgraph)$vector\n\ncgraph_aggregated <- delete_vertices(cgraph, V(cgraph)[size < quantile_graph[10]])\n\n\nset.seed (1234)\nlayout1 <- layout_with_fr(cgraph_aggregated)\n\nquantile_graph_aggregated <- quantile(V(cgraph_aggregated)$size, #identify top 10% of the new vertices\n         probs = seq(0, 1, 1/10)\n         )\n\n\nV(cgraph_aggregated)$color <- ifelse (V(cgraph_aggregated)$size > quantile_graph_aggregated[10], \"darkgoldenrod3\", \"azure3\") #color yellow if vertices is top 10%\nE(cgraph_aggregated)$color <- \"grey\"\nV(cgraph_aggregated)$size <- V(cgraph_aggregated)$size/0.065 \n#Increase the size of nodes based on their centrality score, only those with high score will be visible\n\nV(cgraph_aggregated)$label <- ifelse (V(cgraph_aggregated)$size*0.065 > quantile_graph_aggregated[10],V(cgraph_aggregated)$name,NA)\n#label the vertices if vertices belongs to the top 10%\n\nplot(cgraph_aggregated, edge.arrow.size=0.25,edge.arrow.mode = \"-\", vertex.label = V(cgraph_aggregated)$label, vertex.label.cex = 0.65, vertex.label.font = 1, main = \"Which IDs has the most shipments within 1 year?\" ) \n\n\n\n\n\n\n\nHere we have the attributes of the top 10% vertices based on the updated EigenVector Centrality.\n\n\nShow the code\nvertex_attr(cgraph_aggregated, index = V(cgraph_aggregated)$size*0.065 > quantile_graph_aggregated[10])\n\n\n$name\n[1] \"hǎi dǎn Corporation Wharf\" \"Mar del Este CJSC\"        \n[3] \"Caracola del Sol Services\" \"Coral del Sur Sagl Family\"\n\n$shpcountry\n[1] \"Marebak\"     \"Merigrad\"    \"Puerto Sol\"  \"Solovarossa\"\n\n$rcvcountry\n[1] \"Oceanus\" \"Oceanus\" \"Oceanus\" \"Oceanus\"\n\n$size\n[1]  7.920180 15.384615 12.956742  8.635514\n\n$color\n[1] \"darkgoldenrod3\" \"darkgoldenrod3\" \"darkgoldenrod3\" \"darkgoldenrod3\"\n\n$label\n[1] \"hǎi dǎn Corporation Wharf\" \"Mar del Este CJSC\"        \n[3] \"Caracola del Sol Services\" \"Coral del Sur Sagl Family\"\n\n\n\n\ndetect possible cluster based on the betweeness score of the vertices\n\n\nShow the code\nGNC <- cluster_edge_betweenness(cgraph_aggregated, weights = NULL)\nV(cgraph_aggregated)$color <-membership(GNC)              \ncgraph_aggregated$palette <- diverging_pal(length(GNC)) \nplot(cgraph_aggregated, edge.arrow.size=0.25,edge.arrow.mode = \"-\", vertex.label = NA, main = \"How many Social Groups within the category?\")\n\n\n\n\n\n\n\n\nHere according to the results above, we can make an hypothesis that since FishEye knows from past experience that companies caught fishing illegally will shut down but will then often start up again under a different name, and we find out that companies that have only 1 year of transactions history ofter have the highest avg_price, it is very likely that among these, the trade records may have problems. And we focus on top 10% as it is weird that these companies disappeared in the second year if they fish legally since the trade record is more frequent. These companies and records should be well-studied to further find out more IUU fishing behaviors."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#install-packages-load-data-and-data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#install-packages-load-data-and-data-wrangling",
    "title": "Take-home Exercise 2",
    "section": "2.Install packages, load data and data wrangling",
    "text": "2.Install packages, load data and data wrangling\n\n2.1 Load packages and data\n\npacman::p_load(jsonlite,tidygraph, visNetwork,\n               ggraph, tidyr, ggstatsplot,\n               lubridate, plotly, gganimate, plotly,igraph,\n               DT, tidyverse)\n\n\nMC2 <- jsonlite::fromJSON(\"data/mc2_challenge_graph.json\")\n\n\n\n2.2 Expand MC2 nodes and links\n\nMC2_nodes <- as_tibble(MC2$nodes) %>%\n  distinct() %>%\n  select(id, shpcountry, rcvcountry)\n\nMC2_links <- as_tibble(MC2$links) %>%\n  mutate(ArrivalDate = ymd(arrivaldate)) %>%\n  mutate(Year = year(ArrivalDate)) %>%\n  select(source, target, arrivaldate, Year, hscode, valueofgoods_omu, volumeteu, weightkg, valueofgoodsusd) %>%\n  distinct()\n\n\n\n2.3 Reviewing the imported data\n\nNodes\n\n\nShow the code\nglimpse(MC2_nodes)\n\n\nRows: 34,576\nColumns: 3\n$ id         <chr> \"AquaDelight Inc and Son's\", \"BaringoAmerica Marine Ges.m.b…\n$ shpcountry <chr> \"Polarinda\", NA, \"Oceanus\", NA, \"Oceanus\", \"Kondanovia\", NA…\n$ rcvcountry <chr> \"Oceanus\", NA, \"Oceanus\", NA, \"Oceanus\", \"Utoporiana\", NA, …\n\n\n\n\nEdges\n\n\nShow the code\nglimpse(MC2_links)\n\n\nRows: 5,309,087\nColumns: 9\n$ source           <chr> \"AquaDelight Inc and Son's\", \"AquaDelight Inc and Son…\n$ target           <chr> \"BaringoAmerica Marine Ges.m.b.H.\", \"BaringoAmerica M…\n$ arrivaldate      <chr> \"2034-02-12\", \"2034-03-13\", \"2028-02-07\", \"2028-02-23…\n$ Year             <dbl> 2034, 2034, 2028, 2028, 2028, 2028, 2028, 2028, 2028,…\n$ hscode           <chr> \"630630\", \"630630\", \"470710\", \"470710\", \"470710\", \"47…\n$ valueofgoods_omu <dbl> 141015, 141015, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ volumeteu        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ weightkg         <int> 4780, 6125, 10855, 11250, 11165, 11290, 9000, 19490, …\n$ valueofgoodsusd  <dbl> NA, NA, NA, NA, NA, NA, 87110, 188140, NA, 221110, 58…\n\n\n\n\n\n2.4 Data preview\n\n2.4.1 Preparation for aggregated nodes and edges and select an example hscode and year to create a graph\n\n\nShow the code\nMC2_edges_aggregated <- MC2_links %>%\n  left_join(MC2_nodes, by = c(\"source\" = \"id\")) %>%\n  rename(from = source) %>%\n  left_join(MC2_nodes, by = c(\"target\" = \"id\")) %>%\n  rename(to = target) %>%\n  filter(hscode==\"306170\" & Year==\"2028\")%>%\n  group_by(from, to) %>%\n    summarise(weight = n()) %>%\n  filter(from!=to) %>%\n  filter(weight > 20) %>%\n  ungroup()\nMC2_nodes_aggregated <- MC2_nodes %>%\n  filter(id %in% c(MC2_edges_aggregated$from, MC2_edges_aggregated$to))\n\n\n\nDT::datatable(MC2_nodes_aggregated, class= \"compact\")\n\n\n\n\n\n\n\nDT::datatable(MC2_edges_aggregated, class= \"compact\")\n\n\n\n\n\n\n\n\n2.4.2 Plot the graph\n\n\nShow the code\n#set.seed(123)\n#edges <- MC2_edges_aggregated #%>% sample_frac(0.005)\n#nodes <- MC2_nodes %>%\n  #filter(id %in% c(edges$from, edges$to))\nvisNetwork(MC2_nodes_aggregated,\n           MC2_edges_aggregated ) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualization-and-analysis",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualization-and-analysis",
    "title": "Take-home Exercise 2",
    "section": "3. Visualization and Analysis",
    "text": "3. Visualization and Analysis\n\nAn overview of the temporal change of sampled edges within 2028 to 2034\n\nHere we extract the edge data and group by year-month, and we can see the changes of the sum of weight and value_usd on a monthly changed base.Mostly the sum of weight is below 100k and value_usd below 0.6M.\n\n\nShow the code\nMC2_links$arrivalym <-  format(as.Date(MC2_links$arrivaldate),\"%Y-%m\")\nMC2_edges_5 <- MC2_links %>% group_by(source,target,arrivalym) %>% \n  summarise(count_hscode=n_distinct(hscode),\n            sum_omu=sum(valueofgoods_omu),\n            sum_teu=sum(volumeteu),\n            sum_weightkg=sum(weightkg),\n            sum_usd=sum(valueofgoodsusd),.groups = 'drop') %>%\n  \n  as.data.frame()\nMC2_edges_5 <- MC2_edges_5[complete.cases(MC2_edges_5[ , c('sum_weightkg', 'sum_usd')]), ]\nset.seed(123)\nMC2_nodes_5 <- MC2_nodes %>%\n  filter(id %in% MC2_edges_5$source) %>% sample_frac(0.005)\nMC2_edges_6 <- MC2_edges_5 %>%\n  filter(MC2_edges_5$source %in% MC2_nodes_5$id) %>%\n  filter(sum_weightkg< 2000000) %>%\n  filter(sum_usd< 1000000)\n\n  \nbp <- MC2_edges_6 %>%\n  plot_ly(x = ~sum_weightkg, \n          y = ~sum_usd, \n          size = ~sum_weightkg, \n          color = ~source,\n          sizes = c(2, 100),\n          frame = ~arrivalym, \n          text = ~target, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %>%\n  layout(showlegend = FALSE)\nbp\n\n\n\n\n\n\n\n\n\nComparison of distribution of mean avg_price records that have 1-7 years of history.\n\nHere we pay attention to a yearly change in below and we found that companies that has only 1 year of record has the highest avg_price. Considering if a company is legally fishing, mostly they will form a long relationship with collaborators and the price is reasonable. But for companies that are caught illegal fishing or shut down, the price are more likely to be higher than the market and their record histories are also short.\n\n\nShow the code\nMC2_edges <- MC2_links[complete.cases(MC2_links[ , c('hscode','valueofgoodsusd','volumeteu')]), ] %>% \n  filter(hscode == \"306170\") %>%\n  filter(weightkg != 0 ) %>% \n  mutate(price = valueofgoodsusd/weightkg)\n\nMC2_edges_1 <- MC2_edges %>% \n  group_by(source,target,Year) %>% \n  summarise(No_of_time=n(),\n            sum_omu=sum(valueofgoods_omu),\n            sum_teu=sum(volumeteu),\n            sum_weightkg=sum(weightkg),\n            sum_usd=sum(valueofgoodsusd),\n            mean_price=mean(price),.groups = 'drop') %>%\n  as.data.frame()\n\nMC2_edges_2 <- MC2_edges_1 %>% group_by(source,target) %>% \n  summarise(No_of_year=n_distinct(Year),\n            avg_not=mean(No_of_time),\n            avg_price=mean(mean_price),\n            avg_weightkg=mean(sum_weightkg),.groups = 'drop') %>%\n  #inner_join(edges, by = c(\"source\"=\"from\",\"target\"=\"to\")) %>%\n  as.data.frame()\n\n\nmy_sum <- MC2_edges_2 %>%\n  group_by(No_of_year) %>%\n  summarise(\n    n=n(),\n    mean=mean(avg_price),\n    sd=sd(avg_price)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=No_of_year, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=No_of_year, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean avg_price score by No_of_year\")\n\n\n\n\n\n\n\nStats table\n\n\nShow the code\nknitr::kable(my_sum, format = 'html')\n\n\n\n\n \n  \n    No_of_year \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    1 \n    4387 \n    10.93051 \n    4.400719 \n    0.0664491 \n  \n  \n    2 \n    1410 \n    10.70853 \n    2.746642 \n    0.0731723 \n  \n  \n    3 \n    713 \n    10.82606 \n    2.299127 \n    0.0861634 \n  \n  \n    4 \n    358 \n    10.66151 \n    1.886805 \n    0.0998603 \n  \n  \n    5 \n    250 \n    10.60475 \n    2.499360 \n    0.1583905 \n  \n  \n    6 \n    225 \n    10.58984 \n    1.293865 \n    0.0864500 \n  \n  \n    7 \n    207 \n    10.60920 \n    1.082008 \n    0.0753871 \n  \n\n\n\n\n\n\n\n\nFurther analysis on short-history edges\n\nHere we filter with year=1 and plot out 10%\n\n\nShow the code\nMC2_edges_2_aggregated <- MC2_edges_2 %>%\n  left_join(MC2_nodes, by = c(\"source\" = \"id\")) %>%\n  rename(from = source) %>%\n  left_join(MC2_nodes, by = c(\"target\" = \"id\")) %>%\n  rename(to = target) %>%\n  filter(No_of_year==1)%>%\n  filter(from!=to) %>%\n  filter(avg_not>5)%>%\n  ungroup()\nMC2_nodes_2_aggregated <- MC2_nodes %>%\n  filter(id %in% c(MC2_edges_2_aggregated$from, MC2_edges_2_aggregated$to))\n\nvisNetwork(MC2_nodes_2_aggregated,\n           MC2_edges_2_aggregated ) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\"))\n\n\n\n\n\n\n\n\nthe top 10% vertices based on their eigenvector centrality score\n\n\nShow the code\ncgraph <- graph_from_data_frame (MC2_edges_2_aggregated,\n                           vertices = MC2_nodes_2_aggregated) %>%\n  as_tbl_graph()\nquantile_graph <- quantile(eigen_centrality(cgraph)$vector,\n         probs = seq(0, 1, 1/10)\n         )\nV(cgraph)$size = eigen_centrality(cgraph)$vector\n\ncgraph_aggregated <- delete_vertices(cgraph, V(cgraph)[size < quantile_graph[10]])\n\n\nset.seed (1234)\nlayout1 <- layout_with_fr(cgraph_aggregated)\n\nquantile_graph_aggregated <- quantile(V(cgraph_aggregated)$size, #identify top 10% of the new vertices\n         probs = seq(0, 1, 1/10)\n         )\n\n\nV(cgraph_aggregated)$color <- ifelse (V(cgraph_aggregated)$size > quantile_graph_aggregated[10], \"darkgoldenrod3\", \"azure3\") #color yellow if vertices is top 10%\nE(cgraph_aggregated)$color <- \"grey\"\nV(cgraph_aggregated)$size <- V(cgraph_aggregated)$size/0.065 \n#Increase the size of nodes based on their centrality score, only those with high score will be visible\n\nV(cgraph_aggregated)$label <- ifelse (V(cgraph_aggregated)$size*0.065 > quantile_graph_aggregated[10],V(cgraph_aggregated)$name,NA)\n#label the vertices if vertices belongs to the top 10%\n\nplot(cgraph_aggregated, edge.arrow.size=0.25,edge.arrow.mode = \"-\", vertex.label = V(cgraph_aggregated)$label, vertex.label.cex = 0.65, vertex.label.font = 1, main = \"Which IDs has the most shipments within 1 year?\" ) \n\n\n\n\n\n\n\nHere we have the attributes of the top 10% vertices based on the updated EigenVector Centrality.\n\n\nShow the code\nvertex_attr(cgraph_aggregated, index = V(cgraph_aggregated)$size*0.065 > quantile_graph_aggregated[10])\n\n\n$name\n[1] \"hǎi dǎn Corporation Wharf\" \"Mar del Este CJSC\"        \n[3] \"Caracola del Sol Services\" \"Coral del Sur Sagl Family\"\n\n$shpcountry\n[1] \"Marebak\"     \"Merigrad\"    \"Puerto Sol\"  \"Solovarossa\"\n\n$rcvcountry\n[1] \"Oceanus\" \"Oceanus\" \"Oceanus\" \"Oceanus\"\n\n$size\n[1]  7.920180 15.384615 12.956742  8.635514\n\n$color\n[1] \"darkgoldenrod3\" \"darkgoldenrod3\" \"darkgoldenrod3\" \"darkgoldenrod3\"\n\n$label\n[1] \"hǎi dǎn Corporation Wharf\" \"Mar del Este CJSC\"        \n[3] \"Caracola del Sol Services\" \"Coral del Sur Sagl Family\"\n\n\n\n\ndetect possible cluster based on the betweeness score of the vertices\n\n\nShow the code\nGNC <- cluster_edge_betweenness(cgraph_aggregated, weights = NULL)\nV(cgraph_aggregated)$color <-membership(GNC)              \ncgraph_aggregated$palette <- diverging_pal(length(GNC)) \nplot(cgraph_aggregated, edge.arrow.size=0.25,edge.arrow.mode = \"-\", vertex.label = NA, main = \"How many Social Groups within the category?\")\n\n\n\n\n\n\n\nHere according to the results above, we can make an hypothesis that since FishEye knows from past experience that companies caught fishing illegally will shut down but will then often start up again under a different name, and we find out that companies that have only 1 year of transactions history ofter have the highest avg_price, it is very likely that among these, the trade records may have problems. And we focus on top 10% as it is weird that these companies disappeared in the second year if they fish legally since the trade record is more frequent. These companies and records should be well-studied to further find out more IUU fishing behaviors."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-on Exercise 7",
    "section": "",
    "text": "pacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)\n\n\n\n\n\nattacks <- read_csv(\"data/eventlog.csv\")\n\nRows: 199999 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): source_country, tz\ndttm (1): timestamp\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\n\n\n\n\n\n\nmake_hr_wkday <- function(ts, sc, tz) {\n  real_times <- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt <- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\nwkday_levels <- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks <- attacks %>%\n  group_by(tz) %>%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %>% \n  ungroup() %>% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\n\ngrouped <- attacks %>% \n  count(wkday, hour) %>% \n  ungroup() %>%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\nattacks_by_country <- count(\n  attacks, source_country) %>%\n  mutate(percent = percent(n/sum(n))) %>%\n  arrange(desc(n))\n\n\n\n\n\ntop4 <- attacks_by_country$source_country[1:4]\ntop4_attacks <- attacks %>%\n  filter(source_country %in% top4) %>%\n  count(source_country, wkday, hour) %>%\n  ungroup() %>%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %>%\n  na.omit()\n\n\n\n\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\nair <- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\n\n\nair$month <- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year <- year(ymd(air$`Month-Year`))\n\n\n\n\n\nVietnam <- air %>% \n  select(`Vietnam`, \n         month, \n         year) %>%\n  filter(year >= 2010)\n\n\n\n\n\nhline.data <- Vietnam %>% \n  group_by(month) %>%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\")\n\n\n\n\n\n\n\n\n\n\n\nrice <- read_csv(\"data/rice.csv\")\n\nRows: 550 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Country\ndbl (3): Year, Yield, Production\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nrice %>% \n  mutate(Year = factor(Year)) %>%\n  filter(Year %in% c(1961, 1980)) %>%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\nConverting 'Year' to an ordered factor"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started-1",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started-1",
    "title": "Hands-on Exercise 7",
    "section": "Getting started",
    "text": "Getting started\n\npacman::p_load(ggHoriPlot, ggthemes, tidyverse)\n\n\nStep 1: Data Import\n\naverp <- read_csv(\"data/AVERP.csv\") %>%\n  mutate(`Date` = dmy(`Date`))\n\nRows: 7452 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Date, Consumer Items\ndbl (1): Values\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nStep 2: Plotting the horizon graph\n\naverp %>% \n  filter(Date >= \"2018-01-01\") %>%\n  ggplot() +\n  geom_horizon(aes(x = Date, y=Values), \n               origin = \"midpoint\", \n               horizonscale = 6)+\n  facet_grid(`Consumer Items`~.) +\n    theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n    scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  ggtitle('Average Retail Prices of Selected Consumer Items (Jan 2018 to Dec 2022)')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "pacman::p_load('plotly', 'tidyverse')\nrequire(devtools)\n\nLoading required package: devtools\n\n\nLoading required package: usethis\n\ninstall_version(\"ggtern\", version = \"3.4.1\", repos = \"http://cran.us.r-project.org\")\n\nDownloading package from url: http://cran.us.r-project.org/src/contrib/Archive/ggtern/ggtern_3.4.1.tar.gz\n\n\nvctrs        (0.6.1      -> 0.6.2     ) [CRAN]\nrlang        (1.1.0      -> 1.1.1     ) [CRAN]\nRcppArmad... (0.12.2.0.0 -> 0.12.4.0.0) [CRAN]\nviridisLite  (0.4.1      -> 0.4.2     ) [CRAN]\n\n\nInstalling 4 packages: vctrs, rlang, RcppArmadillo, viridisLite\n\n\nInstalling packages into 'C:/Users/Wang Shengming/AppData/Local/R/win-library/4.2'\n(as 'lib' is unspecified)\n\n\nWarning in i.p(...): installation of package 'rlang' had non-zero exit status\n\n\nWarning in i.p(...): installation of package 'vctrs' had non-zero exit status\n\n\nInstalling package into 'C:/Users/Wang Shengming/AppData/Local/R/win-library/4.2'\n(as 'lib' is unspecified)\n\nlibrary(ggtern)\n\nRegistered S3 methods overwritten by 'ggtern':\n  method           from   \n  grid.draw.ggplot ggplot2\n  plot.ggplot      ggplot2\n  print.ggplot     ggplot2\n\n\n--\nRemember to cite, run citation(package = 'ggtern') for further info.\n--\n\n\n\nAttaching package: 'ggtern'\n\n\nThe following objects are masked from 'package:ggplot2':\n\n    aes, annotate, ggplot, ggplot_build, ggplot_gtable, ggplotGrob,\n    ggsave, layer_data, theme_bw, theme_classic, theme_dark,\n    theme_gray, theme_light, theme_linedraw, theme_minimal, theme_void\n\n\n\n\n\n\n\n\n#Reading the data into R environment\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\nRows: 108126 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): PA, SZ, AG\ndbl (2): Year, Population\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n#Deriving the young, economy active and old measures\nagpop_mutated <- pop_data %>%\n  mutate(`Year` = as.character(Year))%>%\n  spread(AG, Population) %>%\n  mutate(YOUNG = rowSums(.[4:8]))%>%\n  mutate(ACTIVE = rowSums(.[9:16]))  %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018)%>%\n  filter(TOTAL > 0)\n\n\n\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n# reusable function for creating annotation object\nlabel <- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis <- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes <- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %>%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )\n\nNo scatterternary mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#installing-and-launching-r-packages-1",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#installing-and-launching-r-packages-1",
    "title": "Hands-on Exercise 6",
    "section": "Installing and Launching R Packages",
    "text": "Installing and Launching R Packages\n\npacman::p_load(treemap, treemapify, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-wrangling",
    "title": "Hands-on Exercise 6",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nImporting the data set\n\nrealis2018 <- read_csv(\"data/realis2018.csv\")\n\nRows: 23205 Columns: 20\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (12): Project Name, Address, Type of Area, Nett Price($), Sale Date, Pro...\ndbl  (8): No. of Units, Area (sqm), Transacted Price ($), Unit Price ($ psm)...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nGrouped summaries without the Pipe\n\nrealis2018_grouped <- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised <- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n`summarise()` has grouped output by 'Project Name', 'Planning Region',\n'Planning Area', 'Property Type'. You can override using the `.groups`\nargument.\n\n\n\n\nGrouped summaries with the pipe\n\nrealis2018_summarised <- realis2018 %>% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %>%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n`summarise()` has grouped output by 'Project Name', 'Planning Region',\n'Planning Area', 'Property Type'. You can override using the `.groups`\nargument.\n\n\n\n\nDesigning a static treemap\n\nrealis2018_selected <- realis2018_summarised %>%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\nUsing the basic arguments\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\nWorking with vColor and type arguments\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\nThe “value” type treemap\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\nThe “manual” type treemap\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\nWorking with algorithm argument\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\nUsing sortID\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#designing-treemap-using-treemapify-package",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#designing-treemap-using-treemapify-package",
    "title": "Hands-on Exercise 6",
    "section": "Designing Treemap using treemapify Package",
    "text": "Designing Treemap using treemapify Package\n\nDesigning a basic treemap\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\nDefining hierarchy\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\nGroup by Planning Area\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\nAdding boundary line\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#designing-interactive-treemap-using-d3treer",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#designing-interactive-treemap-using-d3treer",
    "title": "Hands-on Exercise 6",
    "section": "Designing Interactive Treemap using d3treeR",
    "text": "Designing Interactive Treemap using d3treeR\n\nInstalling d3treeR package\n\ninstall.packages(\"devtools\")\n\nWarning: package 'devtools' is in use and will not be installed\n\nlibrary(devtools)\ninstall_github(\"timelyportfolio/d3treeR\")\n\nSkipping install of 'd3treeR' from a github remote, the SHA1 (ebb833db) has not changed since last install.\n  Use `force = TRUE` to force installation\n\nlibrary(d3treeR)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#designing-an-interactive-treemap",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#designing-an-interactive-treemap",
    "title": "Hands-on Exercise 6",
    "section": "Designing An Interactive Treemap",
    "text": "Designing An Interactive Treemap\n\ntm <- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\nd3tree(tm,rootname = \"Singapore\" )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands-on Exercise 8",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse)\n\n\n\n\nmpsz <- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\SMLurker\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\npopdata <- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\n\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%>%\nmutate(`AGED`=rowSums(.[16:21])) %>%\nmutate(`TOTAL`=rowSums(.[3:21])) %>%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %>%\n  filter(`ECONOMY ACTIVE` > 0)\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started-1",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started-1",
    "title": "Hands-on Exercise 8",
    "section": "Getting Started",
    "text": "Getting Started\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 8",
    "section": "Geospatial Data Wrangling",
    "text": "Geospatial Data Wrangling\n\nsgpools <- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nRows: 306 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): NAME, ADDRESS, OUTLET TYPE\ndbl (4): POSTCODE, XCOORD, YCOORD, Gp1Gp2 Winnings\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   <chr>          <chr>      <dbl>  <dbl>  <dbl> <chr>                     <dbl>\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\n\nsgpools_sf <- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * <chr>                        <chr>      <dbl> <chr>                     <dbl>\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry <POINT [m]>"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#drawing-proportional-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#drawing-proportional-symbol-map",
    "title": "Hands-on Exercise 8",
    "section": "Drawing Proportional Symbol Map",
    "text": "Drawing Proportional Symbol Map\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n\n\nIt all started with an interactive point symbol map\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\nLets make it proportional\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)\n\nLegend for symbol sizes not available in view mode.\n\n\n\n\n\n\n\n\n\nLets give it a different colour\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)\n\nLegend for symbol sizes not available in view mode.\n\n\n\n\n\n\n\n\n\nI have a twin brothers :)\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\nLegend for symbol sizes not available in view mode.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started-2",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started-2",
    "title": "Hands-on Exercise 8",
    "section": "Getting Started",
    "text": "Getting Started\n\npacman::p_load(tmap, tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-data",
    "title": "Hands-on Exercise 8",
    "section": "Importing data",
    "text": "Importing data\n\nNGA_wp <- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#basic-choropleth-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#basic-choropleth-mapping",
    "title": "Hands-on Exercise 8",
    "section": "Basic Choropleth Mapping",
    "text": "Basic Choropleth Mapping\n\np1 <- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = FALSE)\n\np2 <- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total  water point by LGAs\",\n            legend.outside = FALSE)\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#choropleth-map-for-rates",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#choropleth-map-for-rates",
    "title": "Hands-on Exercise 8",
    "section": "Choropleth Map for Rates",
    "text": "Choropleth Map for Rates\n\nDeriving Proportion of Functional Water Points and Non-Functional Water Points\n\nNGA_wp <- NGA_wp %>%\n  mutate(pct_functional = wp_functional/total_wp) %>%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\nPlotting map of rate\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#extreme-value-maps",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#extreme-value-maps",
    "title": "Hands-on Exercise 8",
    "section": "Extreme Value Maps",
    "text": "Extreme Value Maps\n\nPercentile Map\n\nNGA_wp <- NGA_wp %>%\n  drop_na()\n\npercent <- c(0,.01,.1,.5,.9,.99,1)\nvar <- NGA_wp[\"pct_functional\"] %>%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\nget.var <- function(vname,df) {\n  v <- df[vname] %>% \n    st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\npercentmap <- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent <- c(0,.01,.1,.5,.9,.99,1)\n  var <- get.var(vnam, df)\n  bperc <- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"< 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"> 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\nBox map\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\nboxbreaks <- function(v,mult=1.5) {\n  qv <- unname(quantile(v))\n  iqr <- qv[4] - qv[2]\n  upfence <- qv[4] + mult * iqr\n  lofence <- qv[2] - mult * iqr\n  # initialize break points vector\n  bb <- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence < qv[1]) {  # no lower outliers\n    bb[1] <- lofence\n    bb[2] <- floor(qv[1])\n  } else {\n    bb[2] <- lofence\n    bb[1] <- qv[1]\n  }\n  if (upfence > qv[5]) { # no upper outliers\n    bb[7] <- upfence\n    bb[6] <- ceiling(qv[5])\n  } else {\n    bb[6] <- upfence\n    bb[7] <- qv[5]\n  }\n  bb[3:5] <- qv[2:4]\n  return(bb)\n}\n\nget.var <- function(vname,df) {\n  v <- df[vname] %>% st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\nvar <- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\nboxmap <- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var <- get.var(vnam,df)\n  bb <- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"< 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"> 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nboxmap(\"wp_nonfunctional\", NGA_wp)\n\nWarning: Breaks contains positive and negative values. Better is to use\ndiverging scale instead, or set auto.palette.mapping to FALSE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/data/geospatial/MPSZ-2019.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "pacman::p_load(jsonlite,tidygraph,ggraph,visNetwork,graphlayouts,ggforce,skimr, \n               tidytext,tidyverse,ggstatsplot,ggiraph)\n\n\n\n\n\nmc3_data <- fromJSON(\"data/MC3.json\")\n\n\n\n\n\nmc3_edges <- as_tibble(mc3_data$links) %>%\n  distinct() %>%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type)) %>%\n  group_by(source, target, type) %>%\n  summarise(weights=n()) %>%\n  filter(source!=target) %>%\n  ungroup()\n\n\n\n\n\nmc3_nodes <- as_tibble(mc3_data$nodes) %>%\n  mutate(country = as.character(country),\n         id = as.character(id),\n         product_services = as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu)),\n         type = as.character(type)) %>%\n  select(id, country, type, revenue_omu, product_services)\n\n\n\n\n\n\nShow the code\nskim(mc3_edges)\n\n\n\nData summary\n\n\nName\nmc3_edges\n\n\nNumber of rows\n24036\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nsource\n0\n1\n6\n700\n0\n12856\n0\n\n\ntarget\n0\n1\n6\n28\n0\n21265\n0\n\n\ntype\n0\n1\n16\n16\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nweights\n0\n1\n1\n0\n1\n1\n1\n1\n1\n▁▁▇▁▁\n\n\n\n\n\n\n\n\n\nShow the code\nDT::datatable(mc3_edges)\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = mc3_edges,\n       aes(x = type)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nskim(mc3_nodes)\n\n\n\nData summary\n\n\nName\nmc3_nodes\n\n\nNumber of rows\n27622\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nid\n0\n1\n6\n64\n0\n22929\n0\n\n\ncountry\n0\n1\n2\n15\n0\n100\n0\n\n\ntype\n0\n1\n7\n16\n0\n3\n0\n\n\nproduct_services\n0\n1\n4\n1737\n0\n3244\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrevenue_omu\n21515\n0.22\n1822155\n18184433\n3652.23\n7676.36\n16210.68\n48327.66\n310612303\n▇▁▁▁▁\n\n\n\n\n\n\n\n\n\nShow the code\nDT::datatable(mc3_nodes)\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = mc3_nodes,\n       aes(x = type)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\n\nid1 <- mc3_edges %>%\n  select(source) %>%\n  rename(id = source)\nid2 <- mc3_edges %>%\n  select(target) %>%\n  rename(id = target)\nmc3_nodes1 <- rbind(id1, id2) %>%\n  distinct() %>%\n  left_join(mc3_nodes,\n            unmatched = \"drop\")\n\n\nmc3_graph <- tbl_graph(nodes = mc3_nodes1,\n                       edges = mc3_edges,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness())\n\nmc3_graph %>%\n  filter(betweenness_centrality >= 100000) %>%\nggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    colors = \"lightblue\",\n    alpha = 0.5)) +\n  scale_size_continuous(range=c(1,10))+\n  theme_graph()\n\n\n\n\n\n\n\n\n\n\nmc3_nodes %>% \n    mutate(n_fish = str_count(product_services, \"fish\")) \n\n# A tibble: 27,622 × 6\n   id                          country type  revenue_omu product_services n_fish\n   <chr>                       <chr>   <chr>       <dbl> <chr>             <int>\n 1 Jones LLC                   ZH      Comp…  310612303. Automobiles           0\n 2 Coleman, Hall and Lopez     ZH      Comp…  162734684. Passenger cars,…      0\n 3 Aqua Advancements Sashimi … Oceanus Comp…  115004667. Holding firm wh…      0\n 4 Makumba Ltd. Liability Co   Utopor… Comp…   90986413. Car service, ca…      0\n 5 Taylor, Taylor and Farrell  ZH      Comp…   81466667. Fully electric …      0\n 6 Harmon, Edwards and Bates   ZH      Comp…   75070435. Discount superm…      0\n 7 Punjab s Marine conservati… Riodel… Comp…   72167572. Beef, pork, chi…      0\n 8 Assam   Limited Liability … Utopor… Comp…   72162317. Power and Gas s…      0\n 9 Ianira Starfish Sagl Import Rio Is… Comp…   68832979. Light commercia…      0\n10 Moran, Lewis and Jimenez    ZH      Comp…   65592906. Automobiles, tr…      0\n# ℹ 27,612 more rows\n\n\n\n\n\n\ntoken_nodes <- mc3_nodes %>%\n  unnest_tokens(word, \n                product_services)\n\ntoken_nodes %>%\n  count(word, sort = TRUE) %>%\n  top_n(15) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(x = word, y = n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n      labs(x = \"Count\",\n      y = \"Unique words\",\n      title = \"Count of unique words found in product_services field\")\n\n\n\n\n\n\n\n\n\n\nstopwords_removed <- token_nodes %>% \n  anti_join(stop_words) %>%\n  filter(word %in% c(\"seafood\",\"fish\",\"carp\",\"catfish\",\"herring\",\"mackerel\",\"pollock\",\"salmon\",\"shark\",\"tuna\")) %>%\n  distinct()\nstopwords_removed %>%\n  count(word, sort = TRUE) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(x = word, y = n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n      labs(x = \"Count\",\n      y = \"Unique words\",\n      title = \"Count of unique words found in product_services field\")\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = stopwords_removed,\n       aes(x = type)) +\n  geom_bar()+\n  geom_text(stat=\"count\", \n      aes(label=paste0(after_stat(count))),vjust=-1)+\n  ylim(0,1500)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nclean_nodes_c <-stopwords_removed %>%\n  drop_na(revenue_omu) %>%\n  filter(type==\"Company\")\n\nset.seed(1234)\n\ngghistostats(\n  data = clean_nodes_c,\n  x = revenue_omu,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"revenue_omu\"\n)\n\n\n\n\n\n\n\n\n\n\nShow the code\ndf_nodes <- clean_nodes_c %>% \n  filter(revenue_omu>200000)\ndf_edges <- mc3_edges %>%\n  filter(source %in% df_nodes$id)\n\nid3 <- df_edges %>%\n  select(source) %>%\n  rename(id = source)\nid4 <- df_edges %>%\n  select(target) %>%\n  rename(id = target)\ndf_nodes_1 <- rbind(id3, id4) %>%\n  distinct() %>%\n  left_join(mc3_nodes,\n            unmatched = \"drop\")\n\ndf_graph <- tbl_graph(nodes = df_nodes_1,\n                       edges = df_edges,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness())\n\ng <- df_graph %>%\n  mutate(betweenness_centrality = centrality_betweenness()) %>%\n  ggraph(layout = \"kk\") + \n  geom_edge_link(aes(width=weights), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.01, 0.1)) +\n  geom_node_point(aes(colour = country,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\ndf_edges_1 <- mc3_edges %>%\n  filter(source %in% clean_nodes_c$id)\n\ndf_edges_1r <- df_edges_1 %>%\n  group_by(source) %>%\n  summarize(partners=n_distinct(target)) %>%\n  rename(id=source) %>%\n  ungroup()\n\ndf_nodes_2 <- clean_nodes_c %>% \n  left_join(df_edges_1r) %>%\n  distinct()\n\ndf_nodes_2$partners[is.na(df_nodes_2$partners)] <- -1\n\ndf_nodes_2$group[(df_nodes_2$partners>quantile(df_nodes_2$partners, 0.5)) & (df_nodes_2$revenue_omu<=quantile(df_nodes_2$revenue_omu, 0.8))] <- 1\ndf_nodes_2$group[(df_nodes_2$partners>quantile(df_nodes_2$partners, 0.5)) & (df_nodes_2$revenue_omu>quantile(df_nodes_2$revenue_omu, 0.8))] <- 2\ndf_nodes_2$group[(df_nodes_2$partners<=quantile(df_nodes_2$partners, 0.5)) & (df_nodes_2$revenue_omu<=quantile(df_nodes_2$revenue_omu, 0.8))] <- 3\ndf_nodes_2$group[(df_nodes_2$partners<=quantile(df_nodes_2$partners, 0.5)) & (df_nodes_2$revenue_omu>quantile(df_nodes_2$revenue_omu, 0.8))] <- 4\ndf_nodes_2$group[(df_nodes_2$partners==-1) & (df_nodes_2$revenue_omu<=quantile(df_nodes_2$revenue_omu, 0.8))] <- 5\ndf_nodes_2$group[(df_nodes_2$partners==-1) & (df_nodes_2$revenue_omu>quantile(df_nodes_2$revenue_omu, 0.8))] <- 6\n\n\ndf_nodes_2 <- df_nodes_2[,!names(df_nodes_2) %in% \n      c(\"word\")] %>%\n  distinct() \n\nset.seed(1234)\n\ngghistostats(\n  data = df_nodes_2[df_nodes_2$partners>0,],\n  x = partners,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"partners\")\n\n\n\n\n\n\n\n\n\n\nShow the code\ndf_edges_2 <- mc3_edges %>%\n  filter(source %in% df_nodes_2$id)\n\nid5 <- df_edges_2 %>%\n  select(source) %>%\n  rename(id = source)\nid6 <- df_edges_2 %>%\n  select(target) %>%\n  rename(id = target)\ndf_nodes_3 <- rbind(id5, id6) %>%\n  distinct() %>%\n  left_join(mc3_nodes,\n            unmatched = \"drop\") %>%\n  left_join(df_nodes_2)\n\n\ndf_graph_3 <- tbl_graph(nodes = df_nodes_3,\n                       edges = df_edges_2,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness())\n\ng_3 <- df_graph_3 %>%\n  mutate(betweenness_centrality = centrality_betweenness()) %>%\n  ggraph(layout = \"kk\") + \n  geom_edge_link(aes(width=weights), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.01, 0.1)) +\n  geom_node_point(aes(colour = group,\n            size=betweenness_centrality))\ng_3 + theme_graph()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-json-file-by-using-jsonlite-packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-json-file-by-using-jsonlite-packages",
    "title": "Take-home Exercise 3",
    "section": "Importing JSON file by using jsonlite packages",
    "text": "Importing JSON file by using jsonlite packages\n\nmc3_data <- fromJSON(\"data/MC3.json\")\n\n\nmc3_edges <- as_tibble(mc3_data$links) %>%\n  distinct() %>%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type)) %>%\n  group_by(source, target, type) %>%\n  summarise(weights=n()) %>%\n  filter(source!=target) %>%\n  ungroup()\n\n`summarise()` has grouped output by 'source', 'target'. You can override using\nthe `.groups` argument.\n\n\n\nmc3_nodes <- as_tibble(mc3_data$nodes) %>%\n  mutate(country = as.character(country),\n         id =  as.character(id),\n         product_services = as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu)),\n         type = as.character(type)) %>%\n  select(id, country, type, revenue_omu, product_services)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `revenue_omu = as.numeric(as.character(revenue_omu))`.\nCaused by warning:\n! NAs introduced by coercion"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "pacman::p_load(tidyverse)\n\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x=RACE))+geom_bar()+coord_flip()+theme_minimal() +theme(\n  panel.background = element_rect(fill = \"lightblue\",\n                                colour = \"lightblue\",\n                                size = 0.5, linetype = \"solid\"),\n  panel.grid.major = element_line(size = 0.5, linetype = 'solid',\n                                colour = \"white\"), \n  panel.grid.minor = element_line(size = 0.25, linetype = 'solid',\n                                colour = \"white\")\n)\n\nWarning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)\n\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "title": "Hands-on Exercise 9",
    "section": "",
    "text": "pacman::p_load(lubridate, ggthemes, reactable,\nreactablefmtr, gt, gtExtras, tidyverse)\n\n\n\nlibrary(RODBC)\ncon <- odbcConnectAccess('data/Coffee Chain.mdb')\ncoffeechain <- sqlFetch(con, 'CoffeeChain Query')\nwrite_rds(coffeechain, \"data/CoffeeChain.rds\")\nodbcClose(con)\n\n\n\ncoffeechain <- read_rds(\"data/rds/CoffeeChain.rds\")\nproduct <- coffeechain %>%\n  group_by(`Product`) %>%\n  summarise(`target` = sum(`Budget Sales`),\n            `current` = sum(`Sales`)) %>%\n  ungroup()\n\n\n\nggplot(product, aes(Product, current)) + \n  geom_col(aes(Product, max(target) * 1.01),\n           fill=\"grey85\", width=0.85) +\n  geom_col(aes(Product, target * 0.75),\n           fill=\"grey60\", width=0.85) +\n  geom_col(aes(Product, target * 0.5),\n           fill=\"grey50\", width=0.85) +\n  geom_col(aes(Product, current), \n           width=0.35,\n           fill = \"black\") + \n  geom_errorbar(aes(y = target,\n                    x = Product, \n                    ymin = target,\n                    ymax= target), \n                width = .4,\n                colour = \"red\",\n                size = 1) +\n  coord_flip()\n\n\n\n\n\n\nsales_report <- coffeechain %>%\n  filter(Date >= \"2013-01-01\") %>%\n  mutate(Month = month(Date)) %>%\n  group_by(Month, Product) %>%\n  summarise(Sales = sum(Sales)) %>%\n  ungroup() %>%\n  select(Month, Product, Sales)\nmins <- group_by(sales_report, Product) %>% \n  slice(which.min(Sales))\nmaxs <- group_by(sales_report, Product) %>% \n  slice(which.max(Sales))\nends <- group_by(sales_report, Product) %>% \n  filter(Month == max(Month))\nquarts <- sales_report %>%\n  group_by(Product) %>%\n  summarise(quart1 = quantile(Sales, \n                              0.25),\n            quart2 = quantile(Sales, \n                              0.75)) %>%\n  right_join(sales_report)\n\n\n\nggplot(sales_report, aes(x=Month, y=Sales)) + \n  facet_grid(Product ~ ., scales = \"free_y\") + \n  geom_ribbon(data = quarts, aes(ymin = quart1, max = quart2), \n              fill = 'grey90') +\n  geom_line(size=0.3) +\n  geom_point(data = mins, col = 'red') +\n  geom_point(data = maxs, col = 'blue') +\n  geom_text(data = mins, aes(label = Sales), vjust = -1) +\n  geom_text(data = maxs, aes(label = Sales), vjust = 2.5) +\n  geom_text(data = ends, aes(label = Sales), hjust = 0, nudge_x = 0.5) +\n  geom_text(data = ends, aes(label = Product), hjust = 0, nudge_x = 1.0) +\n  expand_limits(x = max(sales_report$Month) + \n                  (0.25 * (max(sales_report$Month) - min(sales_report$Month)))) +\n  scale_x_continuous(breaks = seq(1, 12, 1)) +\n  scale_y_continuous(expand = c(0.1, 0)) +\n  theme_tufte(base_size = 3, base_family = \"Helvetica\") +\n  theme(axis.title=element_blank(), axis.text.y = element_blank(), \n        axis.ticks = element_blank(), strip.text = element_blank())\n\n\n\n\n\n\nproduct %>%\n  gt::gt() %>%\n  gt_plt_bullet(column = current, \n              target = target, \n              width = 60,\n              palette = c(\"lightblue\", \n                          \"black\")) %>%\n  gt_theme_538()\n\n\n\n\n\n\nreport <- coffeechain %>%\n  mutate(Year = year(Date)) %>%\n  filter(Year == \"2013\") %>%\n  mutate (Month = month(Date, \n                        label = TRUE, \n                        abbr = TRUE)) %>%\n  group_by(Product, Month) %>%\n  summarise(Sales = sum(Sales)) %>%\n  ungroup()\nreport %>%\n  group_by(Product) %>%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\")\nreport %>%\n  group_by(Product) %>%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\") %>%\n   gt() %>%\n   gt_plt_sparkline('Monthly Sales',\n                    same_limit = FALSE)\n\n\n\nreport %>% \n  group_by(Product) %>% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            ) %>%\n  gt() %>%\n  fmt_number(columns = 4,\n    decimals = 2)\n\n\n\nspark <- report %>%\n  group_by(Product) %>%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\")\nsales <- report %>% \n  group_by(Product) %>% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            )\nsales_data = left_join(sales, spark)\n\n\n\nsales_data %>%\n  gt() %>%\n  gt_plt_sparkline('Monthly Sales',\n                   same_limit = FALSE)\n\n\n\nbullet <- coffeechain %>%\n  filter(Date >= \"2013-01-01\") %>%\n  group_by(`Product`) %>%\n  summarise(`Target` = sum(`Budget Sales`),\n            `Actual` = sum(`Sales`)) %>%\n  ungroup() \nsales_data = sales_data %>%\n  left_join(bullet)\nsales_data %>%\n  gt() %>%\n  gt_plt_sparkline('Monthly Sales') %>%\n  gt_plt_bullet(column = Actual, \n                target = Target, \n                width = 28,\n                palette = c(\"lightblue\", \n                          \"black\")) %>%\n  gt_theme_538()\n\n\n\n\n#| warning: false\nremotes::install_github(\"timelyportfolio/dataui\")\nlibrary(dataui)\n\n\nreport <- report %>%\n  group_by(Product) %>%\n  summarize(`Monthly Sales` = list(Sales))\n\nreactable(\n  report,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)\n\n\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)\n\n\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        labels = c(\"first\", \"last\")\n        )\n    )\n  )\n)\n\n\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        statline = \"mean\"\n        )\n    )\n  )\n)\n\n\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        line_width = 1,\n        bandline = \"innerquartiles\",\n        bandline_color = \"green\"\n        )\n    )\n  )\n)\n\n\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkbar(\n        report,\n        highlight_bars = highlight_bars(\n          min = \"red\", max = \"blue\"),\n        bandline = \"innerquartiles\",\n        statline = \"mean\")\n    )\n  )\n)"
  }
]